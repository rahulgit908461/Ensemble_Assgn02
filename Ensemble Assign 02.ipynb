{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48299732-c757-4c22-9cb4-0efb26437472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. How does bagging reduce overfitting in decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f893d0-2641-4059-96f6-b5b5bcf91013",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision trees tend to overfit. To overcome overfitting, pre-pruning or post-pruning methods are used. Bagging \n",
    "#decision trees are also used to prevent overfitting.\n",
    "#Two approaches to avoiding overfitting are distinguished: pre-pruning (generating a tree with fewer branches than\n",
    "#would otherwise be the case) and post-pruning (generating a tree in full and then removing parts of it). Results\n",
    "#are given for pre-pruning using either a size or a maximum depth cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cdc4997-6c4f-44b9-b648-803710abc599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the advantages and disadvantages of using different types of base learners in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad92482-810e-4faf-a754-ff3d3eba2a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging offers the advantage of allowing many weak learners to combine efforts to outdo a single strong learner. \n",
    "#It also helps in the reduction of variance, hence eliminating the overfitting of models in the procedure. \n",
    "#One disadvantage of bagging is that it introduces a loss of interpretability of a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e6ba47-8fc9-47db-bcf6-e8d71f746262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bccc3f1-27ca-42b9-a1f7-afe39cab09d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging reduces the variance without making the predictions biased. This technique acts as a base to many ensemble \n",
    "#techniques so understanding the intuition behind it is crucial.\n",
    "#When we modify the ML algorithm to better fit a given data set, it will in turn lead to low bias but will increase \n",
    "#the variance. This way, the model will fit with the data set while increasing the chances of inaccurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06eeb338-87d4-47a1-b593-3a31724546df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e4a6d17-d960-41d3-b310-7d2067e4f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging avoids overfitting of data and is used for both regression and classification models, specifically for \n",
    "#decision tree algorithms.\n",
    "#Bagging is a method of merging the same type of predictions. Boosting is a method of merging different types of\n",
    "#predictions. Bagging decreases variance, not bias, and solves over-fitting issues in a model. Boosting decreases \n",
    "#bias, not variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371c243c-75a2-4a21-9106-471436fe4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2b02978-5ab3-474e-b28e-ec6c1b147b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging, also known as bootstrap aggregation, is the ensemble learning method that is commonly used to reduce \n",
    "#variance within a noisy dataset. In bagging, a random sample of data in a training set is selected with \n",
    "#replacementâ€”meaning that the individual data points can be chosen more than once.\n",
    "#There are no restrictions/guidelines on the number of models. You can start even from 3 models. You can keep the\n",
    "#number of models as a hyperparameter if the training cost is less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c89a1f63-ab6f-4ebf-8aa9-8b65f0eb626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6. Can you provide an example of a real-world application of bagging in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e11d1-dabc-4e69-bab3-d1c1e7e1ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
